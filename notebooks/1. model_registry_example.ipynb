{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "# private key to access the storage account \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='./keyfile.json' # Specify the gcs authentification file path \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-1.19.0-py3-none-any.whl (14.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.4 MB 14.6 MB/s eta 0:00:01   |██████████████████▊             | 8.4 MB 5.9 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-macosx_10_9_x86_64.whl (249 kB)\n",
      "\u001b[K     |████████████████████████████████| 249 kB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gunicorn\n",
      "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.1-cp37-cp37m-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.9 MB 147 kB/s  eta 0:00:01    |█▏                              | 593 kB 14.9 MB/s eta 0:00:02     |███████████▉                    | 6.2 MB 14.9 MB/s eta 0:00:01     |███████████████████████████████▊| 16.8 MB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Flask\n",
      "  Using cached Flask-2.0.1-py3-none-any.whl (94 kB)\n",
      "Collecting docker>=4.0.0\n",
      "  Using cached docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
      "Collecting alembic<=1.4.1\n",
      "  Using cached alembic-1.4.1.tar.gz (1.1 MB)\n",
      "Collecting querystring-parser\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting click>=7.0\n",
      "  Using cached click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Collecting protobuf>=3.7.0\n",
      "  Using cached protobuf-3.17.3-cp37-cp37m-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Using cached databricks-cli-0.14.3.tar.gz (54 kB)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Using cached prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n",
      "Collecting entrypoints\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.0-cp37-cp37m-macosx_10_9_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 30.0 MB/s eta 0:00:01    |████████████████▏               | 5.7 MB 30.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz\n",
      "  Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.19-py3-none-any.whl (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sqlparse>=0.3.1\n",
      "  Using cached sqlparse-0.4.1-py3-none-any.whl (42 kB)\n",
      "Collecting requests>=2.17.3\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting packaging\n",
      "  Downloading packaging-21.0-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 8.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.22-cp37-cp37m-macosx_10_14_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 14.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cloudpickle\n",
      "  Using cached cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
      "Collecting python-editor>=0.3\n",
      "  Using cached python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting python-dateutil\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[K     |████████████████████████████████| 247 kB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.6.1-py3-none-any.whl (17 kB)\n",
      "Collecting tabulate>=0.7.7\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting six>=1.10.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 10.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
      "  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Using cached smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 19.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.3-py3-none-any.whl (35 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 9.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.0-cp37-cp37m-macosx_10_14_x86_64.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 5.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting Jinja2>=3.0\n",
      "  Using cached Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.0.1-cp37-cp37m-macosx_10_9_x86_64.whl (13 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from gunicorn->mlflow) (52.0.0.post20210125)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.5.0-py3-none-any.whl (5.7 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting prometheus_client\n",
      "  Using cached prometheus_client-0.11.0-py2.py3-none-any.whl (56 kB)\n",
      "Building wheels for collected packages: alembic, databricks-cli, prometheus-flask-exporter\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=50231e743d3967d9fb16532754340f7c7bc4411f63d31fdf5108b9b3a0a448c8\n",
      "  Stored in directory: /Users/kaislaribi/Library/Caches/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100555 sha256=daf472f55d289706f11ece976ef0e119ff46bf232cc21196b95496cb26a2de2a\n",
      "  Stored in directory: /Users/kaislaribi/Library/Caches/pip/wheels/3b/60/14/6930445b08959fbdf4e3029bac7e1f2cccb2e94df8afa00b29\n",
      "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17399 sha256=b18ef4b9979e7733010216f1e6ff82667d4c13cd9777384550e8dd9d5dfba2ba\n",
      "  Stored in directory: /Users/kaislaribi/Library/Caches/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\n",
      "Successfully built alembic databricks-cli prometheus-flask-exporter\n",
      "Installing collected packages: zipp, typing-extensions, MarkupSafe, importlib-metadata, Werkzeug, urllib3, smmap, six, Jinja2, itsdangerous, idna, greenlet, click, charset-normalizer, websocket-client, tabulate, sqlalchemy, requests, pytz, python-editor, python-dateutil, pyparsing, prometheus-client, numpy, Mako, gitdb, Flask, sqlparse, querystring-parser, pyyaml, protobuf, prometheus-flask-exporter, pandas, packaging, gunicorn, gitpython, entrypoints, docker, databricks-cli, cloudpickle, alembic, mlflow\n",
      "Successfully installed Flask-2.0.1 Jinja2-3.0.1 Mako-1.1.4 MarkupSafe-2.0.1 Werkzeug-2.0.1 alembic-1.4.1 charset-normalizer-2.0.3 click-8.0.1 cloudpickle-1.6.0 databricks-cli-0.14.3 docker-5.0.0 entrypoints-0.3 gitdb-4.0.7 gitpython-3.1.19 greenlet-1.1.0 gunicorn-20.1.0 idna-3.2 importlib-metadata-4.6.1 itsdangerous-2.0.1 mlflow-1.19.0 numpy-1.21.1 packaging-21.0 pandas-1.3.0 prometheus-client-0.11.0 prometheus-flask-exporter-0.18.2 protobuf-3.17.3 pyparsing-2.4.7 python-dateutil-2.8.2 python-editor-1.0.4 pytz-2021.1 pyyaml-5.4.1 querystring-parser-1.2.4 requests-2.26.0 six-1.16.0 smmap-4.0.0 sqlalchemy-1.4.22 sqlparse-0.4.1 tabulate-0.8.9 typing-extensions-3.10.0.0 urllib3-1.26.6 websocket-client-1.1.0 zipp-3.5.0\n",
      "Collecting google-cloud\n",
      "  Downloading google_cloud-0.34.0-py2.py3-none-any.whl (1.8 kB)\n",
      "Installing collected packages: google-cloud\n",
      "Successfully installed google-cloud-0.34.0\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-1.41.1-py2.py3-none-any.whl (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-core<3.0dev,>=1.6.0\n",
      "  Downloading google_cloud_core-1.7.1-py2.py3-none-any.whl (28 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-auth<3.0dev,>=1.24.0\n",
      "  Downloading google_auth-1.33.1-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from google-cloud-storage) (2.26.0)\n",
      "Collecting google-resumable-media<3.0dev,>=1.3.0\n",
      "  Downloading google_resumable_media-1.3.1-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 7.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /Users/kaislaribi/.local/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.24.0->google-cloud-storage) (3.4.2)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.24.0->google-cloud-storage) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from google-auth<3.0dev,>=1.24.0->google-cloud-storage) (52.0.0.post20210125)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 16.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-core<2.0.0dev,>=1.21.0\n",
      "  Downloading google_api_core-1.31.0-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 2.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 20.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage) (3.17.3)\n",
      "Requirement already satisfied: pytz in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage) (2021.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage) (21.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Using cached google_crc32c-1.1.2-cp37-cp37m-macosx_10_14_x86_64.whl (27 kB)\n",
      "Collecting cffi>=1.0.0\n",
      "  Downloading cffi-1.14.6-cp37-cp37m-macosx_10_9_x86_64.whl (176 kB)\n",
      "\u001b[K     |████████████████████████████████| 176 kB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<3.0dev,>=1.6.0->google-cloud-storage) (2.4.7)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 8.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.0.3)\n",
      "Installing collected packages: pyasn1, pycparser, pyasn1-modules, cachetools, googleapis-common-protos, google-auth, cffi, google-crc32c, google-api-core, google-resumable-media, google-cloud-core, google-cloud-storage\n",
      "Successfully installed cachetools-4.2.2 cffi-1.14.6 google-api-core-1.31.0 google-auth-1.33.1 google-cloud-core-1.7.1 google-cloud-storage-1.41.1 google-crc32c-1.1.2 google-resumable-media-1.3.1 googleapis-common-protos-1.53.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.20\n",
      "Collecting xgboost\n",
      "  Using cached xgboost-1.4.2-py3-none-macosx_10_14_x86_64.macosx_10_15_x86_64.macosx_11_0_x86_64.whl (1.2 MB)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.0-cp37-cp37m-macosx_10_9_x86_64.whl (31.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.9 MB 6.3 MB/s eta 0:00:01    |▎                               | 235 kB 5.1 MB/s eta 0:00:07     |█████████████████▏              | 17.1 MB 7.5 MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/kaislaribi/anaconda3/envs/mlflow-serving-example/lib/python3.7/site-packages (from xgboost) (1.21.1)\n",
      "Installing collected packages: scipy, xgboost\n",
      "Successfully installed scipy-1.7.0 xgboost-1.4.2\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip install mlflow\n",
    "!pip install google-cloud \n",
    "!pip install google-cloud-storage\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Version: 1.14.1\n",
      "MLflow Tracking URI: http://loadbalancerip\n",
      "XGBoost version: 0.90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "\n",
    "mlflow.set_tracking_uri('http://loadbalancerip') # Change to Mlflow URI  (loadbalancer ip)\n",
    "print(\"MLflow Version:\", mlflow.__version__)\n",
    "print(\"MLflow Tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\"XGBoost version:\",xgb.__version__)\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and register a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    train, test = train_test_split(data, test_size=0.3, random_state=1)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    X_train, X_test = train.drop([\"quality\"], axis=1), test.drop([\"quality\"], axis=1)\n",
    "    y_train, y_test = train[\"quality\"], test[\"quality\"]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_path, max_depth, min_child_weight, estimators, model_name):\n",
    "    X_train, X_test, y_train, y_test = build_data(data_path)\n",
    "    with mlflow.start_run() as run:\n",
    "        # Start mlflow session\n",
    "        run_id = run.info.run_uuid\n",
    "        experiment_id = run.info.experiment_id\n",
    "        print(\"MLflow:\")\n",
    "        print(\"  run_id:\", run_id)\n",
    "        print(\"  experiment_id:\", experiment_id)\n",
    "        print(\"  experiment_name:\", client.get_experiment(experiment_id).name)\n",
    "\n",
    "        # MLflow params\n",
    "        print(\"Parameters:\")\n",
    "        print(\"  max_depth:\", max_depth)\n",
    "        print(\"  min_child_weight:\", min_child_weight)\n",
    "        print(\"  estimators:\", estimators)\n",
    "        \n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"min_child_weight\", min_child_weight)\n",
    "        mlflow.log_param(\"estimators\", estimators)\n",
    "\n",
    "        # Create and fit model\n",
    "        model = xgb.XGBRegressor(\n",
    "                 max_depth=max_depth,\n",
    "                 min_child_weight=min_child_weight,\n",
    "                 random_state=42) \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # MLflow metrics\n",
    "        predictions = model.predict(X_test)\n",
    "        print(\"predictions:\",predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        print(\"Metrics:\")\n",
    "        print(\"  rmse:\", rmse)\n",
    "        print(\"  mae:\", mae)\n",
    "        print(\"  r2:\", r2)\n",
    "        \n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.xgboost.log_model(model, \"xgboost-model\", registered_model_name = model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow:\n",
      "  run_id: b66effdfef4e477ebacb3859a32b424a\n",
      "  experiment_id: 0\n",
      "  experiment_name: Exp1\n",
      "Parameters:\n",
      "  max_depth: 10\n",
      "  min_child_weight: 1\n",
      "  estimators: 100\n",
      "predictions: [5.930445  6.9174986 6.943309  ... 6.4364724 6.987052  5.6387153]\n",
      "Metrics:\n",
      "  rmse: 0.6605505923590334\n",
      "  mae: 0.44089301443424356\n",
      "  r2: 0.44297057516776106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'xgb_0'.\n",
      "2021/07/16 11:28:41 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: xgb_0, version 1\n",
      "Created version '1' of model 'xgb_0'.\n"
     ]
    }
   ],
   "source": [
    "data_path = './wine-quality-white.csv'\n",
    "experiment_name = 'test_xgboost'\n",
    "model_name = 'xgb_0'\n",
    "max_depth = 10\n",
    "min_child_weight = 1\n",
    "estimators = 100\n",
    "train(data_path, max_depth , min_child_weight, estimators, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model from mlflow and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.0004535, 5.994977 , 5.629604 , 5.9799094, 5.9799094],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict on a Pandas DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test_samples =pd.read_csv(data_path).head(5).drop(columns=['quality'])\n",
    "loaded_model = mlflow.pyfunc.load_model(\"runs:/a0928931dff54a829b881be2a3e41d00/xgboost-model\")\n",
    "loaded_model.predict(test_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
